{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Preprocessing and Model Selection\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, MinMaxScaler, PolynomialFeatures\n",
    "from category_encoders import TargetEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Models\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "# Evaluation Metrics\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, confusion_matrix, classification_report, roc_auc_score, precision_score, recall_score, f1_score\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "\n",
    "# Saving models\n",
    "import joblib\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Surface         Winner               Loser    WPts    LPts   W1  \\\n",
      "0 2023-01-01    Hard       Giron M.          Gasquet R.   776.0   740.0  7.0   \n",
      "1 2023-01-01    Hard    Mcdonald M.          Galan D.E.   775.0   741.0  6.0   \n",
      "2 2023-01-02    Hard  Kecmanovic M.        O Connell C.  1420.0   652.0  6.0   \n",
      "3 2023-01-02    Hard    Nishioka Y.             Rune H.  1134.0  2888.0  2.0   \n",
      "4 2023-01-02    Hard     Popyrin A.  Auger-Aliassime F.   469.0  4195.0  6.0   \n",
      "\n",
      "    L1   W2   L2   W3   L3  W4  L4  W5  L5  AvgW  AvgL  \n",
      "0  6.0  6.0  7.0  7.0  5.0 NaN NaN NaN NaN  1.89  1.89  \n",
      "1  3.0  NaN  NaN  NaN  NaN NaN NaN NaN NaN  1.36  3.12  \n",
      "2  4.0  6.0  4.0  NaN  NaN NaN NaN NaN NaN  1.58  2.36  \n",
      "3  6.0  6.0  4.0  6.0  4.0 NaN NaN NaN NaN  3.56  1.29  \n",
      "4  4.0  7.0  6.0  NaN  NaN NaN NaN NaN NaN  6.04  1.13  \n"
     ]
    }
   ],
   "source": [
    "\n",
    "def read_files_to_dataframe(directory, years):\n",
    "    data_frames = []\n",
    "\n",
    "    for year in years:\n",
    "        file_path = os.path.join(directory, f\"{year}.xlsx\")\n",
    "        try:\n",
    "            # Read the Excel file into a DataFrame\n",
    "            df = pd.read_excel(file_path)\n",
    "            df['Year'] = year  # Add a column for the year\n",
    "            data_frames.append(df)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"File {file_path} not found. Skipping.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "    # Concatenate all DataFrames into a single DataFrame\n",
    "    combined_df = pd.concat(data_frames, ignore_index=True)\n",
    "    return combined_df\n",
    "\n",
    "\n",
    "data_dir = \"../Raw_historical_data\"\n",
    "file_years = range(2023, 2025)  \n",
    "\n",
    "historical_data_df = read_files_to_dataframe(data_dir, file_years)\n",
    "historical_data_df = historical_data_df[['Date', 'Surface', 'Winner', 'Loser', 'WPts', 'LPts', 'W1', 'L1', 'W2', 'L2', 'W3', 'L3','W4','L4','W5','L5', 'AvgW', 'AvgL']]\n",
    "\n",
    "print(historical_data_df.head())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Date Surface             P1                  P2   P1Pts   P2Pts  P1S1  \\\n",
      "0 2023-01-01    Hard       Giron M.          Gasquet R.   776.0   740.0   7.0   \n",
      "1 2023-01-01    Hard     Galan D.E.         Mcdonald M.   741.0   775.0   3.0   \n",
      "2 2023-01-02    Hard  Kecmanovic M.        O Connell C.  1420.0   652.0   6.0   \n",
      "3 2023-01-02    Hard        Rune H.         Nishioka Y.  2888.0  1134.0   6.0   \n",
      "4 2023-01-02    Hard     Popyrin A.  Auger-Aliassime F.   469.0  4195.0   6.0   \n",
      "\n",
      "   P2S1  P1S2  P2S2  P1S3  P2S3  P1S4  P2S4  P1S5  P2S5  AvgP1  AvgP2  \\\n",
      "0   6.0   6.0   7.0   7.0   5.0   0.0   0.0   0.0   0.0   1.89   1.89   \n",
      "1   6.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   0.0   3.12   1.36   \n",
      "2   4.0   6.0   4.0   0.0   0.0   0.0   0.0   0.0   0.0   1.58   2.36   \n",
      "3   2.0   4.0   6.0   4.0   6.0   0.0   0.0   0.0   0.0   1.29   3.56   \n",
      "4   4.0   7.0   6.0   0.0   0.0   0.0   0.0   0.0   0.0   6.04   1.13   \n",
      "\n",
      "   WinnerLabel  \n",
      "0            1  \n",
      "1            0  \n",
      "2            1  \n",
      "3            0  \n",
      "4            1  \n"
     ]
    }
   ],
   "source": [
    "# Create a copy to flip every second row\n",
    "flipped_df = historical_data_df.copy()\n",
    "\n",
    "# Flip Winner/Loser columns in every second row\n",
    "flipped_df.loc[1::2, ['Winner', 'Loser']] = historical_data_df.loc[1::2, ['Loser', 'Winner']].values\n",
    "\n",
    "# Flip points, ranks, and set scores\n",
    "flipped_df.loc[1::2, ['WPts', 'LPts']] = historical_data_df.loc[1::2, ['LPts', 'WPts']].values\n",
    "flipped_df.loc[1::2, ['W1', 'L1']] = historical_data_df.loc[1::2, ['L1', 'W1']].values\n",
    "flipped_df.loc[1::2, ['W2', 'L2']] = historical_data_df.loc[1::2, ['L2', 'W2']].values\n",
    "flipped_df.loc[1::2, ['W3', 'L3']] = historical_data_df.loc[1::2, ['L3', 'W3']].values\n",
    "flipped_df.loc[1::2, ['W4', 'L4']] = historical_data_df.loc[1::2, ['L4', 'W4']].values\n",
    "flipped_df.loc[1::2, ['W5', 'L5']] = historical_data_df.loc[1::2, ['L5', 'W5']].values\n",
    "flipped_df.loc[1::2, ['AvgW', 'AvgL']] = historical_data_df.loc[1::2, ['AvgL', 'AvgW']].values\n",
    "\n",
    "# Create a new Winner column (1 if P1 wins, 0 otherwise)\n",
    "flipped_df['WinnerLabel'] = (flipped_df['Winner'] == historical_data_df['Winner']).astype(int)\n",
    "\n",
    "# Rename columns to P1S1, P2S1, etc.\n",
    "flipped_df = flipped_df.rename(columns={\n",
    "    'W1': 'P1S1', 'L1': 'P2S1',\n",
    "    'W2': 'P1S2', 'L2': 'P2S2',\n",
    "    'W3': 'P1S3', 'L3': 'P2S3',\n",
    "    'W4': 'P1S4', 'L4': 'P2S4',\n",
    "    'W5': 'P1S5', 'L5': 'P2S5'\n",
    "})\n",
    "\n",
    "flipped_df[['P1S1', 'P2S1', 'P1S2', 'P2S2', 'P1S3', 'P2S3', 'P1S4', 'P2S4', 'P1S5', 'P2S5']] = flipped_df[['P1S1', 'P2S1', 'P1S2', 'P2S2', 'P1S3', 'P2S3', 'P1S4', 'P2S4', 'P1S5', 'P2S5']].fillna(0)\n",
    "\n",
    "\n",
    "# Rename Winner and Loser to P1 and P2\n",
    "flipped_df = flipped_df.rename(columns={'Winner': 'P1', 'Loser': 'P2', 'WPts':'P1Pts', 'LPts':'P2Pts', 'AvgW':'AvgP1' , 'AvgL':'AvgP2' })\n",
    "\n",
    "\n",
    "# Display the first few rows\n",
    "print(flipped_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'RANK_P1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\amine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3805\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3804\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 3805\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_engine\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcasted_key\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   3806\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m err:\n",
      "File \u001b[1;32mindex.pyx:167\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mindex.pyx:196\u001b[0m, in \u001b[0;36mpandas._libs.index.IndexEngine.get_loc\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7081\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mpandas\\\\_libs\\\\hashtable_class_helper.pxi:7089\u001b[0m, in \u001b[0;36mpandas._libs.hashtable.PyObjectHashTable.get_item\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RANK_P1'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[30], line 285\u001b[0m\n\u001b[0;32m    282\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_df\n\u001b[0;32m    284\u001b[0m \u001b[38;5;66;03m# Example usage\u001b[39;00m\n\u001b[1;32m--> 285\u001b[0m new_df \u001b[38;5;241m=\u001b[39m \u001b[43mpreprocess_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfirst_row_index\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m3759\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    286\u001b[0m new_df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtransformed_data.csv\u001b[39m\u001b[38;5;124m'\u001b[39m, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[30], line 31\u001b[0m, in \u001b[0;36mpreprocess_data\u001b[1;34m(first_row_index)\u001b[0m\n\u001b[0;32m     28\u001b[0m p2 \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mP2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     30\u001b[0m \u001b[38;5;66;03m# Identifying Player Ranks :\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m rank_p1 \u001b[38;5;241m=\u001b[39m \u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mRANK_P1\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     32\u001b[0m rank_p2 \u001b[38;5;241m=\u001b[39m row[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mRANK_P2\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m     34\u001b[0m \u001b[38;5;66;03m# Identifying Surface type :\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\amine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1121\u001b[0m, in \u001b[0;36mSeries.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   1118\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[key]\n\u001b[0;32m   1120\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m key_is_scalar:\n\u001b[1;32m-> 1121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_value\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1123\u001b[0m \u001b[38;5;66;03m# Convert generator to list before going through hashable part\u001b[39;00m\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;66;03m# (We will iterate through the generator there to check for slices)\u001b[39;00m\n\u001b[0;32m   1125\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_iterator(key):\n",
      "File \u001b[1;32mc:\\Users\\amine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\series.py:1237\u001b[0m, in \u001b[0;36mSeries._get_value\u001b[1;34m(self, label, takeable)\u001b[0m\n\u001b[0;32m   1234\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[label]\n\u001b[0;32m   1236\u001b[0m \u001b[38;5;66;03m# Similar to Index.get_value, but we do not fall back to positional\u001b[39;00m\n\u001b[1;32m-> 1237\u001b[0m loc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_loc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabel\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1239\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_integer(loc):\n\u001b[0;32m   1240\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_values[loc]\n",
      "File \u001b[1;32mc:\\Users\\amine\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\pandas\\core\\indexes\\base.py:3812\u001b[0m, in \u001b[0;36mIndex.get_loc\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3807\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(casted_key, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m (\n\u001b[0;32m   3808\u001b[0m         \u001b[38;5;28misinstance\u001b[39m(casted_key, abc\u001b[38;5;241m.\u001b[39mIterable)\n\u001b[0;32m   3809\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28many\u001b[39m(\u001b[38;5;28misinstance\u001b[39m(x, \u001b[38;5;28mslice\u001b[39m) \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m casted_key)\n\u001b[0;32m   3810\u001b[0m     ):\n\u001b[0;32m   3811\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m InvalidIndexError(key)\n\u001b[1;32m-> 3812\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(key) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01merr\u001b[39;00m\n\u001b[0;32m   3813\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m:\n\u001b[0;32m   3814\u001b[0m     \u001b[38;5;66;03m# If we have a listlike key, _check_indexing_error will raise\u001b[39;00m\n\u001b[0;32m   3815\u001b[0m     \u001b[38;5;66;03m#  InvalidIndexError. Otherwise we fall through and re-raise\u001b[39;00m\n\u001b[0;32m   3816\u001b[0m     \u001b[38;5;66;03m#  the TypeError.\u001b[39;00m\n\u001b[0;32m   3817\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_indexing_error(key)\n",
      "\u001b[1;31mKeyError\u001b[0m: 'RANK_P1'"
     ]
    }
   ],
   "source": [
    "df = flipped_df\n",
    "\n",
    "def preprocess_data(first_row_index):\n",
    "\n",
    "    # Extract unique player names from the dataset\n",
    "    unique_players = pd.concat([df['P1'], df['P2']]).unique()\n",
    "\n",
    "    # Initialize dictionaries to store running totals and counts using player names as keys\n",
    "    total_points_diff = {player: 0 for player in unique_players}\n",
    "    sets_played = {player: 0 for player in unique_players}\n",
    "    matches_played = {player: 0 for player in unique_players}\n",
    "    win_record = {player: [] for player in unique_players}\n",
    "    h2h_records = {(p1, p2): {'outcomes': [], 'matches': 0} \n",
    "                   for p1 in unique_players for p2 in unique_players if p1 != p2}\n",
    "    surface_stats = {player: {'Hard': {'wins': 0, 'games': 0}, \n",
    "                              'Clay': {'wins': 0, 'games': 0}, \n",
    "                              'Grass': {'wins': 0, 'games': 0}} \n",
    "                     for player in unique_players}\n",
    "\n",
    "    # Process the initial rows to populate dictionaries\n",
    "    initial_df = df.iloc[:first_row_index]\n",
    "    \n",
    "    #region DICTIONARIES FILLING WITH INITIAL DATA\n",
    "    for _, row in initial_df.iterrows():\n",
    "\n",
    "        # Identifying players of the row :\n",
    "        p1 = row['P1']\n",
    "        p2 = row['P2']\n",
    "\n",
    "        # Identifying Player Points :\n",
    "        ATP_Points_p1 = row['P1Pts']\n",
    "        ATP_Points_p2 = row['P2Pts']\n",
    "\n",
    "        # Identifying Surface type :\n",
    "        surface = row['Surface']\n",
    "\n",
    "        # Row points score calculation\n",
    "        points_diff_p1 = (\n",
    "            (row['P1S1'] - row['P2S1']) +\n",
    "            (row['P1S2'] - row['P2S2']) +\n",
    "            (row['P1S3'] - row['P2S3']) +\n",
    "            (row['P1S4'] - row['P2S4']) +\n",
    "            (row['P1S5'] - row['P2S5'])\n",
    "        )\n",
    "\n",
    "        # Dictionnary points diff counting updating : \n",
    "        total_points_diff[p1] += points_diff_p1\n",
    "        total_points_diff[p2] -= points_diff_p1  \n",
    "\n",
    "        # Row Sets Number Calculation\n",
    "        sets_played_p1 = (\n",
    "            (row['P1S1'] > 0) + \n",
    "            (row['P1S2'] > 0) + \n",
    "            (row['P1S3'] > 0) + \n",
    "            (row['P1S4'] > 0) + \n",
    "            (row['P1S5'] > 0)\n",
    "        )\n",
    "\n",
    "        sets_played_p2 = (\n",
    "            (row['P2S1'] > 0) + \n",
    "            (row['P2S2'] > 0) + \n",
    "            (row['P2S3'] > 0) + \n",
    "            (row['P2S4'] > 0) + \n",
    "            (row['P2S5'] > 0)\n",
    "        )\n",
    "\n",
    "        # Dictionary sets number updating, max in case of 6-0\n",
    "        sets_played[p1] += max(sets_played_p1, sets_played_p2)\n",
    "        sets_played[p2] += max(sets_played_p1, sets_played_p2)\n",
    "\n",
    "        # Dictionary sets number updating.\n",
    "        matches_played[p1] += 1\n",
    "        matches_played[p2] += 1\n",
    "\n",
    "        # Row winner identification:\n",
    "        winner = row['Winner']\n",
    "\n",
    "        # Dictionary updating with win or loss for both row players : \n",
    "        if np.abs(ATP_Points_p1 - ATP_Points_p2) <= 500:\n",
    "            win_record[p1].append(1 if winner == 1 else 0)\n",
    "            win_record[p2].append(1 if winner == 2 else 0)\n",
    "\n",
    "        # Dictionary updating incrementing matches number for p1 p2 and adding outcomes of game:\n",
    "        h2h_records[(p1, p2)]['matches'] += 1\n",
    "        h2h_records[(p2, p1)]['matches'] += 1\n",
    "        if winner == 1:\n",
    "            h2h_records[(p1, p2)]['outcomes'].append(1)\n",
    "            h2h_records[(p2, p1)]['outcomes'].append(0)\n",
    "        elif winner == 2:\n",
    "            h2h_records[(p1, p2)]['outcomes'].append(0)\n",
    "            h2h_records[(p2, p1)]['outcomes'].append(1)\n",
    "\n",
    "        # Dict updating for Surface Stats only if player Ranks close:\n",
    "        if np.abs(rank_p1 - rank_p2) <= 50:\n",
    "            surface_stats[p1][surface]['games'] += 1\n",
    "            surface_stats[p2][surface]['games'] += 1\n",
    "            if winner == 1:\n",
    "                surface_stats[p1][surface]['wins'] += 1\n",
    "            elif winner == 2:\n",
    "                surface_stats[p2][surface]['wins'] += 1\n",
    "    #endregion\n",
    "\n",
    "    # Initialize a new DataFrame to store the transformed rows\n",
    "    new_df = pd.DataFrame(columns=[\n",
    "        'P1',\n",
    "        'P2',\n",
    "        'ATP_P1_Pts', \n",
    "        'ATP_P2_Pts', \n",
    "        'DIFF_ATP_Pts', #### \n",
    "        'AVG_P1', \n",
    "        'AVG_P2', \n",
    "        'DIFF_AVG', ####\n",
    "        'Num_Data_Points_AVG_P1_P2', \n",
    "        'WR_P1',\n",
    "        'WR_P2',\n",
    "        'DIFF_WR', ####\n",
    "        'Num_Data_Points_WR_P1_P2',\n",
    "        'H2H_P1P2', ####\n",
    "        'Num_Data_Points_H2H',\n",
    "        'Surface_WR_P1',\n",
    "        'Surface_WR_P2',\n",
    "        'DIFF_Surface_WR_P1_P2', ####\n",
    "        'Surface',\n",
    "        'Num_Data_Points_Surface_P1_P2',\n",
    "        'Winner'\n",
    "        'B365P1'\n",
    "        'B365P2'\n",
    "    ])\n",
    "\n",
    "    # Loop through each remaining row\n",
    "    for i in range(first_row_index, len(df)):\n",
    "\n",
    "        initial_df = df.iloc[:i+1]\n",
    "\n",
    "        #region USING CURRENT VERSION OF DICTIONARIES TO CREATE PROCESSED CURRENT ROW:\n",
    "\n",
    "        # Selecting current row and identifying p1 and p2\n",
    "        game = initial_df.iloc[-1]\n",
    "        p1 = game['P1']\n",
    "        p2 = game['P2']\n",
    "\n",
    "        # Lookup skills for p1 and p2\n",
    "        rank_p1 = game['RANK_P1']\n",
    "        rank_p2 = game['RANK_P2']\n",
    "\n",
    "        # Using processed dictionaries to calculate avg points diff of each player : \n",
    "        avg_p1 = total_points_diff[p1] / sets_played[p1] if sets_played[p1] != 0 else 0\n",
    "        avg_p2 = total_points_diff[p2] / sets_played[p2] if sets_played[p2] != 0 else 0\n",
    "\n",
    "       \n",
    "        # Summing the last 10 matches outcomes 1 or 0 :\n",
    "        wr_p1 = sum(win_record[p1][-10:]) / len(win_record[p1][-10:]) if len(win_record[p1][-10:]) > 0 else 0\n",
    "        wr_p2 = sum(win_record[p2][-10:]) / len(win_record[p2][-10:]) if len(win_record[p2][-10:]) > 0 else 0\n",
    "\n",
    "\n",
    "        # Rounding the win-Ratio : \n",
    "        wr_p1 = round(wr_p1, 2)\n",
    "        wr_p2 = round(wr_p2, 2) \n",
    "\n",
    "        # Get the data points number for calculating wr : \n",
    "        num_points_wr_p1 = len(win_record[p1][-10:])\n",
    "        num_points_wr_p2 = len(win_record[p2][-10:])\n",
    "\n",
    "        # Ensure there are at least 10 games or use the available number of matches for H2H\n",
    "        h2h_matches = min(10, h2h_records[(p1, p2)]['matches'])\n",
    "        h2h_outcomes = h2h_records[(p1, p2)]['outcomes'][-h2h_matches:]\n",
    "        h2h_wins = sum(h2h_outcomes)\n",
    "\n",
    "        # Calculate the H2H ratio\n",
    "        h2h_p1_p2 = h2h_wins / h2h_matches if h2h_matches > 0 else 0\n",
    "\n",
    "        # Calculate surface-specific win ratios for the current match's surface\n",
    "        surface = game['Surface']\n",
    "        surface_wr_p1 = surface_stats[p1][surface]['wins'] / surface_stats[p1][surface]['games'] if surface_stats[p1][surface]['games'] > 0 else 0\n",
    "        surface_wr_p2 = surface_stats[p2][surface]['wins'] / surface_stats[p2][surface]['games'] if surface_stats[p2][surface]['games'] > 0 else 0\n",
    "\n",
    "        num_points_surface_p1 = surface_stats[p1][surface]['games']\n",
    "        num_points_surface_p2 = surface_stats[p2][surface]['games']\n",
    "\n",
    "        # Create the transformed row for the current game\n",
    "        transformed_row = {\n",
    "            'P1': p1,\n",
    "            'P2': p2,\n",
    "            'RANK_P1': rank_p1,\n",
    "            'RANK_P2' : rank_p2,\n",
    "            'DIFF_RANK' : rank_p2 - rank_p1,\n",
    "            'AVG_P1': round(avg_p1,2),\n",
    "            'AVG_P2': round(avg_p2,2),\n",
    "            'DIFF_AVG': round(avg_p1-avg_p2,2),\n",
    "            'Num_Points_AVG_P1_P2': (matches_played[p1],  matches_played[p2]),\n",
    "            'WR_P1': round(wr_p1,2),\n",
    "            'WR_P2': round(wr_p2,2),\n",
    "            'DIFF_WR': round(wr_p1-wr_p2,2),\n",
    "            'Num_Points_WR_P1_P2': (num_points_wr_p1, num_points_wr_p2),\n",
    "            'H2H_P1P2': round(h2h_p1_p2,2),\n",
    "            'Num_Points_H2H': h2h_matches,\n",
    "            'Surface_WR_P1': round(surface_wr_p1, 2),\n",
    "            'Surface_WR_P2': round(surface_wr_p2,2),\n",
    "            'DIFF_Surface_WR_P1_P2': round(surface_wr_p1 - surface_wr_p2,2),\n",
    "            'Surface': surface,\n",
    "            'Num_Points_Surface_P1_P2': (num_points_surface_p1, num_points_surface_p2),\n",
    "            'Winner': game['Winner'],\n",
    "            'B365P1' : game['B365P1'],\n",
    "            'B365P2' : game['B365P2']\n",
    "        }\n",
    "        \n",
    "        #endregion\n",
    "\n",
    "        new_df = pd.concat([new_df, pd.DataFrame([transformed_row])], ignore_index=True)\n",
    "\n",
    "        #region USING CURRENT ROW DATA TO UPDATE DICTIONNARIES AND BE USED IN NEXT ROW : \n",
    "\n",
    "        # Row points score calculation\n",
    "\n",
    "        points_diff_p1 = (\n",
    "            (game['P1S1'] - game['P2S1']) +\n",
    "            (game['P1S2'] - game['P2S2']) +\n",
    "            (game['P1S3'] - game['P2S3']) +\n",
    "            (game['P1S4'] - game['P2S4']) +\n",
    "            (game['P1S5'] - game['P2S5'])\n",
    "        )\n",
    "\n",
    "        # Dictionary points diff counting updating : \n",
    "        total_points_diff[p1] += points_diff_p1\n",
    "        total_points_diff[p2] -= points_diff_p1  \n",
    "\n",
    "        # Row Sets Number Calculation\n",
    "        sets_played_p1 = (\n",
    "            (game['P1S1'] > 0) + \n",
    "            (game['P1S2'] > 0) + \n",
    "            (game['P1S3'] > 0) + \n",
    "            (game['P1S4'] > 0) + \n",
    "            (game['P1S5'] > 0)\n",
    "        )\n",
    "\n",
    "        sets_played_p2 = (\n",
    "            (game['P2S1'] > 0) + \n",
    "            (game['P2S2'] > 0) + \n",
    "            (game['P2S3'] > 0) + \n",
    "            (game['P2S4'] > 0) + \n",
    "            (game['P2S5'] > 0)\n",
    "        )\n",
    "\n",
    "        # Dictionary sets number updating, max in case of 6-0\n",
    "        sets_played[p1] += max(sets_played_p1, sets_played_p2)\n",
    "        sets_played[p2] += max(sets_played_p1, sets_played_p2)\n",
    "\n",
    "        # Dictionary sets number updating.\n",
    "        matches_played[p1] += 1\n",
    "        matches_played[p2] += 1\n",
    "\n",
    "        # Row winner identification :\n",
    "        winner = game['Winner']\n",
    "\n",
    "        # Dictionary updating with win or loss for both row players : \n",
    "        if np.abs(rank_p1 - rank_p2) <= 50:\n",
    "            win_record[p1].append(1 if winner == 1 else 0)\n",
    "            win_record[p2].append(1 if winner == 2 else 0)\n",
    "\n",
    "        # Dictionary updating incrementing matches number for p1 p2 and adding outcomes of game :\n",
    "        h2h_records[(p1, p2)]['matches'] += 1\n",
    "        h2h_records[(p2, p1)]['matches'] += 1\n",
    "        if winner == 1:\n",
    "            h2h_records[(p1, p2)]['outcomes'].append(1)\n",
    "            h2h_records[(p2, p1)]['outcomes'].append(0)\n",
    "        elif winner == 2:\n",
    "            h2h_records[(p1, p2)]['outcomes'].append(0)\n",
    "            h2h_records[(p2, p1)]['outcomes'].append(1)\n",
    "\n",
    "\n",
    "        # Dict updating for Surface Stats only if player Ranks close:\n",
    "        if np.abs(rank_p1 - rank_p2) <= 50:\n",
    "            surface_stats[p1][surface]['games'] += 1\n",
    "            surface_stats[p2][surface]['games'] += 1\n",
    "            if winner == 1:\n",
    "                surface_stats[p1][surface]['wins'] += 1\n",
    "            elif winner == 2:\n",
    "                surface_stats[p2][surface]['wins'] += 1\n",
    "\n",
    "        #endregion\n",
    "\n",
    "    return new_df\n",
    "\n",
    "# Example usage\n",
    "new_df = preprocess_data(first_row_index = 3759)\n",
    "new_df.to_csv('transformed_data.csv', index=False)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
